---
title: "Stuff I Enjoyed in 2025 - Publications & Writing"
date: 2026-01-27
description:  Reflecting on the publications and articles I enjoyed in 2025
---

Continuing my (delayed) 2025 reflection series with the publications and articles I most enjoyed reading in 2025. Previously: [Stuff I Enjoyed in 2025 - Books](https://www.disnetdev.com/blog/2026-01-16-stuff-i-enjoyed-in-2025-books/).

My religious read for the year was [Garbage Day](https://www.garbageday.email/). They do a great job of contextualizing the wild and frustrating events in an entertaining way. Also great is [Today in Tabs](https://www.todayintabs.com/) with such sharp writing.

The (semi)political writers I followed included [John Ganz](https://www.unpopularfront.news/), [Henry Farrell](https://www.programmablemutter.com/), and [Dave Karpf](https://davekarpf.substack.com/).

[The Digital Antiquarian](https://www.filfre.net/) has also been a really fun read going through the archives of old games. [The Space Sim's Last Hurrah](https://www.filfre.net/2025/11/the-space-sims-last-hurrah/) and [Alpha Centauri](https://www.filfre.net/2025/06/alpha-centauri/) in particular were great. *Alpha Centauri* and *Freespace 2* were two of my favorite games growing up and essentially no one remembers them.

To make sense of all the AI developments [Simon Willison's](https://simonwillison.net/) blog was indispensable. Also great was [Cognitive Resonance](https://www.cognitiveresonance.net/) putting things in a cognitive science framework, [AI Snake Oil/AI as Normal Technology](https://www.normaltech.ai/) and their seminal [AI as Normal Technology](https://knightcolumbia.org/content/ai-as-normal-technology) article, Ethan Mollick from [One Useful Thing](https://www.oneusefulthing.org/) (taken with a grain of salt), and [Venkatesh Rao](https://contraptions.venkateshrao.com/) for seeing someone explore going all in without being a complete grifter.

Favorite articles:

(note: I'm not necessarily cosigning the claims or ideas of any of these articles. They just got me thinking the most in 2025.)

[We're getting the social media crisis wrong](https://www.programmablemutter.com/p/were-getting-the-social-media-crisis?publication_id=1745679&post_id=154328417&isFreemail=true&r=qcnxw&triedRedirect=true&__readwiseLocation=)

> The fundamental problem, as I see it, is not that social media *misinforms individuals* about what is true or untrue but that it creates *publics with malformed collective understandings*.

This reframing is just great.

[Be Slightly Monstrous](https://contraptions.venkateshrao.com/p/be-slightly-monstrous?publication_id=9973&post_id=180215443&isFreemail=true&r=1dcd14&triedRedirect=true)

> The real conceit here is about consciously surrendering to a machinic reshaping of your patterns of cognition. Your ways of seeing. Your ways of feeling into reality.

He's exploring something interesting here. Not sure I like it but it's interesting.

[Revenge of the Dilettantes](https://contraptions.venkateshrao.com/p/revenge-of-the-dilettantes?publication_id=9973&post_id=182114230&isFreemail=true&r=1dcd14&triedRedirect=true)

> The future is *bespokeness.*

The claim is something like AI is in the process of driving the cost of production so low that there won't be any reason not to spin up bespoke productions for basically any creative output.

[Why Some Students Learn Faster](https://fivetwelvethirteen.substack.com/p/why-some-students-learn-faster?__readwiseLocation=)

> Researchers divide intelligence into two parts: crystallized intelligence and fluid intelligence. Crystallized intelligence refers to how much you know: knowing things makes you smarter. [...] Fluid intelligence is a broad term for how well we can think and reason when we don’t have crystallized intelligence to rely on.

I hadn't come across the distinction between crystallized and fluid intelligence before so this was a bit of a revelation for me.
 
[The Bookmaker](https://thepointmag.com/politics/the-bookmaker/?__readwiseLocation=)

> But what Silver willfully ignores is that the successful players in this world aren’t the bettors. They are the bookies and casino owners—the house that never loses.

Gambling is bad.
 
[My AI Skeptic Friends Are All Nuts](https://fly.io/blog/youre-all-nuts/?__readwiseLocation=)

> Some of the smartest people I know share a bone-deep belief that AI is a fad — the next iteration of NFT mania. I’ve been reluctant to push back on them, because, well, they’re smarter than me. But their arguments are unserious, and worth confronting. Extraordinarily talented people are doing work that LLMs already do better, out of spite.

My read is that the consensus has definitively shifted after the release of Opus 4.5 at the end of the year to acknowledge coding agents are good actually but during the year there was a lot of *discourse*. This was my favorite piece trying to convince the skeptics. 

[The Zizians and the Rationalist death cults](https://maxread.substack.com/p/the-zizians-and-the-rationalist-death?publication_id=392873&post_id=156012376&isFreemail=true&r=1dcd14&triedRedirect=true)

> Feeling comfortable with your own epistemological position, even if you know it’s flawed, is not the preferred mode for Rationalist development, but it’s pretty foundational to building a stable sense of self. By the same token, the ability to dismiss an argument with a “that sounds nuts,” without needing recourse to a point-by-point rebuttal, is anathema to the rationalist project. But it’s a pretty important skill to have if you want to avoid joining cults.

I think this is a sharp insight into one of the flaws inherent to the Rationalist community.

[AI as Normal Technology](https://knightcolumbia.org/content/ai-as-normal-technology)

This was probably the most important article about AI in 2025. A well thought through middle path between "the singularity is coming in [2027](https://ai-2027.com/)" and "AI is a fad like NFTs".
